<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="">
<meta name="author" content="">
<title>ActivityNet Challenge</title>
<!-- core CSS -->
<link href="../../css/bootstrap.min.css" rel="stylesheet">
<link href="../../css/font-awesome.min.css" rel="stylesheet">
<link href="../../css/animate.min.css" rel="stylesheet">
<link href="../../css/owl.carousel.css" rel="stylesheet">
<link href="../../css/owl.transitions.css" rel="stylesheet">
<link href="../../css/prettyPhoto.css" rel="stylesheet">
<link href="css/main.css" rel="stylesheet">
<link href="../../css/responsive.css" rel="stylesheet">
<link href='http://fonts.googleapis.com/css?family=Roboto+Condensed:400,300,700' rel='stylesheet' type='text/css'>
<link href='http://fonts.googleapis.com/css?family=Droid+Sans+Mono' rel='stylesheet' type='text/css'>
<link rel="shortcut icon" media="all" type="image/x-icon" href="../../images/favicon.png" >

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-76841323-1', 'auto');
  ga('send', 'pageview');

</script>


<style>
pre {
   background-color: ghostwhite;
   border: 1px solid #CCCCCC;
   padding: 10px 20px;
   margin: 30px;
   }
.json-key {
   color: #F54E4E;
   }
.json-value {
   color: #666666;
   }
.json-string {
   color: #666666;
   }
.json-comment {
   color: #71BC78;
   }

  #rcorners2 {
  border-radius: 6px 6px 6px 6px;
  -moz-border-radius: 6px 6px 6px 6px;
  -webkit-border-radius: 6px 6px 6px 6px;
  border: 1px solid #CCCCCC;
   }



</style>

</head><!--/head-->
<body id="home" class="homepage">
  <header id="header">
    <nav id="main-menu" class="navbar navbar-default navbar-fixed-top" role="banner">
      <div class="container">

        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="index.html"><img src="images/ChallengeLogo.svg" class="d-inline-black-align-top" height="50" width="auto" alt="logo"></a>
        </div>

        <div class="collapse navbar-collapse navbar-right" style="font-size:13px">
          <ul compact class="nav navbar-nav">
            <li class="scroll"><a href="index.html">Home</a></li>
            <li class="scroll"><a href="people.html">People</a></li>
            <li class="scroll"><a href="program.html">Program</a></li>
            <!--<li class="scroll"><a href="program.html">Program</a></li>-->
            <li class="scroll active"><a href="#">Challenge Description</a></li>
            <li class="scroll"><a href="evaluation.html">Evaluation</a></li>
            <li class="scroll"><a href="contacus.html">Contact Us</a></li>


          </ul>
            <a class="navbar-brand" href="http://cvpr2017.thecvf.com/" target="_blank"><img src="images/cvpr17.png" align="top"  width="188" height="65" alt="logo"></a>
        </div>
      </div><!--/.container-->
    </nav><!--/nav-->
  </header><!--/header-->


  <!-- GUIDELINES PAGE -->

  <section id="guidelines">
    <div>
      <div class="container">

          <div class="col-sm-10 col-sm-offset-1 wow fadeInDown">
            <h2>Challenge Guidelines</h2>
            <p>
                To enter the competition, you need to create an account on the <a href="evaluation.html"> Evaluation Tab</a>.
                Using a registered account you will be able to upload your results to the evaluation server and participate in
              the ActivityNet Challenge 2017. <b style="text-decoration: line-through;">Please be advised that we have changed our submission policy this year: each participant 
              is limited to 1 submission per task per week. The Evaluation Server will enforce a waiting time of 7 days between submissions of the same task. 
              This gives each participant a total of 3 submissions per task before the evaluation server closes.</b> <b> Each team is limited to 4 submissions (in total) per task.</b> Only results that are submitted during the challenge period (before the deadline)
                and posted to the leaderboard will be considered valid. Additionally, you will also need to upload
                a notebook paper that describes your method in detail. This challenge allows the use of external data to train and tune
                algorithm parameters. We are committed to keeping track of this practice. Therefore, each submission must explicitly
                cite the kind of external data used and which modules benefit from it.
            </p>
          </div>

          <div class="col-sm-10 col-sm-offset-1 wow fadeInDown">
            <h2>Challenge Tasks</h2>
            <p>The ActivityNet challenge 2017 includes five different tasks as described below:</p>
            <h4>Task 1: Untrimmed Video Classification (ActivityNet)</h4>
            <p>This task is intended to evaluate the ability of algorithms to predict activities in <b>untrimmed</b> video sequences. Here, videos can
            contain more than one activity, and typically large time lapses of the video are not related with any activity of interest. <a href='untrimmed.html'>[Details]</a>
            </p>
            <h4>Task 2: Trimmed Action Recognition (Kinetics) <b style="color: #4575b4;">[New]</b></h4>
            <p>This task is intended to evaluate the ability of algorithms to recognize activities in <b>trimmed</b> video sequences. Here, videos contain
            a single activity, and all the clips have a standard duration of ten seconds. For this task, participants will use the Kinetics
            dataset, a new large-scale benchmark for trimmed action classification. <a href='trimmed.html'>[Details]</a>
            </p>
            <h4>Task 3: Temporal Action Proposals (ActivityNet) <b style="color: #4575b4;">[New]</b></h4>
            <p>This task is intended to evaluate the ability of algorithms to generate high quality <b> action proposals </b>. The goal is to produce
            a set of candidate temporal segments that are likely to contain a human action. <a href='proposals.html'>[Details]</a>
            </p>
            <h4>Task 4: Temporal Action Localization (ActivityNet)</h4>
            <p>This task is intended to evaluate the ability of algorithms to <b>temporally localize activities in untrimmed video sequences</b>. Here, videos
            can contain more than one activity instance, and mutiple activity categories can appear in the video. <a href='localization.html'>[Details]</a>
            </p>
            <h4>Task 5: Dense-Captioning Events in Videos (ActivityNet Captions) <b style="color: #4575b4;">[New]</b></h4>
            <p>This task involves both <b>detecting and describing events</b> in a video. For this task, participants will use the ActivityNet
            Captions dataset, a new large-scale benchmark for dense-captioning events. <a href='captioning.html'>[Details]</a>
            </p>
          </div>

          <div class="col-sm-10 col-sm-offset-1 wow fadeInDown">
            <h2 id='Features'>Additional Data</h2>

            <h4>Global features (Task [1, 3-5])</h4>
            <li>
              <b>ImagenetShuffle.</b> We provide CNN features based on the pool5 layer of a
              Google inception net (GoogLeNet) at a rate of 2FPS.
              Features are mean-pooled across the frames followed by L1-normalization.
              <a href='download.html#imshuffle'>[Download]</a>
            </li>
            <li>
              <b>MBH Features.</b>
              The MBH features are generated with the aid of the Improved
              Trajectories executable with a provided implementation by the authors.
              Then, features are encoded using the GMM + Fisher Vectors pipeline.
              <a href='download.html#mbh'>[Download]</a>
            </li>
            <h4>Frame based features (Task [1, 3-5])</h4>

            <li>
              <b>C3D.</b> The publicly available pre-trained C3D model, which has
              a temporal resolution of 16 frames, is used to extract frame based
              features. This network is not fine-tuned on the data in the challenge. We reduce the
              dimensionality of the activations from the second fully-connected
              layer (fc7) of the visual encoder from 4096 to 500 dimensions using PCA.
              <a href='download.html#c3d'>[Download]</a>
            </li>

            <h4>Temporal action proposals (Task [1, 3-5])</h4>
            <li>
              <b>Agnostic Temporal Activity Proposals.</b> We  provide these proposals to encourage participation
              in the Activity Detection task. These proposals could be applied
              as a preliminary stage to split the untrimmed videos into high recall
              trimmed temporal segments.
              <a href='download.html#proposals'>[Download]</a>
            </li>

          </div>

         <div class=" col-sm-10 col-sm-offset-1 wow fadeInDown">
           <h2 id='use_external_data_policy'>Use of External Data Policy</h2>
              <p>
              This challenge allows participants to use external data to train their algorithms or tune parameters.
              Each submission should explicitly cite the kind of external data used and which modules of the system benefit from it.
              Some popular forms of external data usage include (but not confined to):
              <ul>
                <li> additional videos or images for tuning parameters, and
                </li>
                <li> external modules like CNNs or DPMs trained with other datasets.
                </li>
              </ul>
              If your case is not listed above, please contact us as soon as possible.
              </p>
        </div>


         <div class="col-sm-10 col-sm-offset-1 wow fadeInDown">
           <h2 id='honor_code'>Honor Code</h2>
              <p>
              This academic challenge aims to highlight automated algorithms that understand the audio-visual content of videos.
              To serve this purpose and to allow for fair competition, we request that ALL participants:
              <ul>
                <li> generate results on the testing set by analyzing audio-visual content <b>only</b>,
                </li>
                <li> <b>not</b> use the testing set for training or parameter tuning, and
                </li>
                <li> refrain from using <b>any</b> auxiliary information of the testing set (e.g. human annotations, URL metadata, etc.) other than the provided videos themselves.
                </li>
              </ul>
                If a submission is found to violate any of the above guidelines, the challenge organizers reserve the right to disqualify the violating team.
              </p>
        </div>


        <div class="col-sm-10 col-sm-offset-1 wow fadeInDown">
           <h2 id='honor_code'>Most Innovative Solution</h2>
              <p>
This year, we will award a Panasonic Lumix DC-GH5 camera (+lens) and an Nvidia graphics card to the participant with the most innovative solution. This solution does not necessarily have to be the winner of any task. A technical committee will make this decision based on the participants' submitted reports. So, please make sure to submit a detailed description of your solution on time. 
              </p>
        </div>

</div>
</div>
  </section><!--/#guidelines-->


  <script src="../../js/jquery.js"></script>
  <script src="../../js/bootstrap.min.js"></script>
  <script src="../../js/owl.carousel.min.js"></script>
  <script src="../../js/mousescroll.js"></script>
  <script src="../../js/smoothscroll.js"></script>
  <script src="../../js/jquery.prettyPhoto.js"></script>
  <script src="../../js/jquery.isotope.min.js"></script>
  <script src="../../js/jquery.inview.min.js"></script>
  <script src="../../js/wow.min.js"></script>
  <script src="../../js/main.js"></script>

</body>
</html>
