<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="">
<meta name="author" content="">
<title>ActivityNet Challenge</title>
<!-- core CSS -->
<link href="../../css/bootstrap.min.css" rel="stylesheet">
<link href="../../css/font-awesome.min.css" rel="stylesheet">
<link href="../../css/animate.min.css" rel="stylesheet">
<link href="../../css/owl.carousel.css" rel="stylesheet">
<link href="../../css/owl.transitions.css" rel="stylesheet">
<link href="../../css/prettyPhoto.css" rel="stylesheet">
<link href="css/main.css" rel="stylesheet">
<link href="../../css/responsive.css" rel="stylesheet">
<link href='http://fonts.googleapis.com/css?family=Roboto+Condensed:400,300,700' rel='stylesheet' type='text/css'>
<link href='http://fonts.googleapis.com/css?family=Droid+Sans+Mono' rel='stylesheet' type='text/css'>
<!--[if lt IE 9]>
<script src="js/html5shiv.js"></script>
<script src="js/respond.min.js"></script>
<![endif]-->
<link rel="shortcut icon" media="all" type="image/x-icon" href="../../images/favicon.png" >

<style>
pre {
   background-color: ghostwhite;
   border: 1px solid #CCCCCC;
   padding: 10px 20px;
   margin: 30px;
   }
.json-key {
   color: #F54E4E;
   }
.json-value {
   color: #666666;
   }
.json-string {
   color: #666666;
   }
.json-comment {
   color: #71BC78;
   }

  #rcorners2 {
  border-radius: 6px 6px 6px 6px;
  -moz-border-radius: 6px 6px 6px 6px;
  -webkit-border-radius: 6px 6px 6px 6px;
  border: 1px solid #CCCCCC;
   }



</style>

</head><!--/head-->

<body id="home" class="homepage">
  <header id="header">
    <nav id="main-menu" class="navbar navbar-default navbar-fixed-top" role="banner">
      <div class="container">

        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="index.html"><img src="images/activity-logo-challenge.png" alt="logo"></a>
        </div>

        <div class="collapse navbar-collapse navbar-right"  style="font-size:13px">
          <ul class="nav navbar-nav">
            <li class="scroll"><a href="index.html">Home</a></li>
            <li class="scroll"><a href="people.html">People</a></li>
            <li class="scroll"><a href="dates.html">Important Dates</a></li>
            <!--<li class="scroll"><a href="program.html">Program</a></li>-->
            <li class="scroll active"><a href="guidelines.html">Challenge Description</a></li>
            <!--<li class="scroll"><a href="evaluation.html">Evaluation</a></li>-->
            <li class="scroll"><a href="contacus.html">Contact Us</a></li>

          </ul>
          <!--<a class="navbar-brand" href="http://cvpr2017.thecvf.com/" target="_blank"><img src="images/CVPRLogo.png" style="margin:15px 0px" align="bottom"  width="200" height="30" alt="logo"></a>-->
          <a class="navbar-brand" href="http://cvpr2017.thecvf.com/" target="_blank"><img src="images/cvpr17.png" align="top"  width="188" height="65" alt="logo"></a>
        </div>
      </div><!--/.container-->
    </nav><!--/nav-->
  </header><!--/header-->


  <!-- DATE PAGE -->

  <section id="dates">
    <div>
      <div class="container">
        <div class="row">

          <div class=" col-sm-10 col-sm-offset-1 wow fadeInDown">
            <h2>Task 5: Dense-Captioning Events in Videos</h2>
            <p>
            Most natural videos contain numerous events. For example, in a video of a 'man playing a piano', the video might also contain another 'man dancing' or 'a crowd clapping'. This challenge studies the task of dense-captioning events, which involves both detecting and describing events in a video. This challenge uses the ActivityNet Captions dataset, a new large-scale benchmark for dense-captioning events. ActivityNet Captions contains 20K videos amounting to 849 video hours with 100K total descriptions, each with its unique start and end time.
            </p>
            <p><b>For information related to this task, please contact: </b> <a href="mailto:ranjay.krishna@gmail.com?Subject=CaptivityNet Challenge" target="_top">ranjay.krishna@gmail.com</a>,
            <a href="mailto:kenjihata@cs.stanford.edu?Subject=ActivityNet Challenge" target="_top">kenjihata@cs.stanford.edu</a>
          </p>
            <h3> Dataset </h3>
            <p>
            The <a target="_blank" href='http://cs.stanford.edu/people/ranjaykrishna/densevid/'>ActivityNet Captions dataset</a> will be used for this challenge. The dataset connects videos to a series of temporally annotated sentence descriptions. Each sentence covers a unique segment of the video, describing multiple events that occur. These events may occur over very long or short periods of time and are not limited in any capacity, allowing them to co-occur. On average, each of the 20K videos in Captivity Net contains 3.65 temporally localized sentences, resulting in a total of 100K sentences. We find that the number of sentences per video follows a relatively normal distribution. Furthermore, as the video duration increases, the number of sentences also increases. Each sentence has an average length of 13.48 words, which is also normally distributed.
            </p>

            <h3> Evaluation Metric </h3>
            <p>
            The evaluation code used by the evaluation server can be <a target="_blank" href='http://github.com/ranjaykrishna/densevid_eval.git'>found here</a>.</br>
            Inspired by the dense-image captioning metric, we use a similar metric to measure the joint ability of our model to both localize and caption events. This metric computes the average precision (AP) across tIoU thresholds of 0.3, 0.5, and 0.7, when captioning the top 1000 proposals. We measure precision of our captions using traditional evaluation metrics: Bleu, METEOR and CIDEr.
            </p>

            <h3> Baselines </h3>
            Baseline results are available in <a target="_blank" href="http://cs.stanford.edu/people/ranjaykrishna/densevid"> the paper available here </a>.

            <h3> Submission Format </h3>
            <p>
            Please follow the following JSON format when submitting your results for the challenge:
            </p>


          <pre>
<code>{
<span class="json-key" >version</span>: <span class="json-string">"VERSION 1.0"</span>,
<span class="json-key">results</span>: {
  <span class="json-key"><q>v_5n7NCViB5TU</q></span>: [
      {
      <span class="json-key">sentence</span>: <span class="json-string">"One player moves all around the net holding the ball"</span>,<span class="json-comment"> # String description of an event. </span>
      <span class="json-key">timestamp</span>: [<span class="json-value">1.23</span>,<span class="json-value">4.53</span>]<span class="json-comment"> # The start and end times of the event (in seconds).</span>
      },
      {
      <span class="json-key">sentence</span>: <span class="json-string">"A small group of men are seen running around a basketball court playing a game"</span>.
      <span class="json-key">timestamp</span>: [<span class="json-value">5.24</span>, <span class="json-value">18.23</span>]
      }
  ]
}
<span class="json-key">external_data</span>: {
  <span class="json-key">used</span>: <span class="json-bool">true,</span><span class="json-comment"> # Boolean flag. True indicates the use of external data.</span>
  <span class="json-key">details</span>: <span class="json-string">"First fully-connected layer from VGG-16 pre-trained on ILSVRC-2012 training set",</span><span class="json-comment"> # This string details what kind of external data you used and how you used it.</span>
}
}</code>
            </pre>


          <p>
          The example above is illustrative. Comments must be removed in your submission. You can <a target="_blank" href="https://raw.githubusercontent.com/ranjaykrishna/densevid_eval/master/sample_submission.json" download> download here </a> a sample submission file.
          </p>

          <h3> Awards </h3>
          <p> The winner of Task 5 (dense-captioning events in videos) will receive 2,000 USD, a Panasonic Lumix DC-GH5 camera (+lens), an Nvidia graphics card, and a Qualcomm gift. </p>

          </div>


        </div>
      </div>
    </div>
  </section><!--/#dates-->

  <script src="../../js/jquery.js"></script>
  <script src="../../js/bootstrap.min.js"></script>
  <script src="../../js/owl.carousel.min.js"></script>
  <script src="../../js/mousescroll.js"></script>
  <script src="../../js/smoothscroll.js"></script>
  <script src="../../js/jquery.prettyPhoto.js"></script>
  <script src="../../js/jquery.isotope.min.js"></script>
  <script src="../../js/jquery.inview.min.js"></script>
  <script src="../../js/wow.min.js"></script>
  <script src="../../js/main.js"></script>

</body>
</html>
