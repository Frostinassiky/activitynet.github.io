<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">
    <title>Challenge Description | ActivityNet Large Scale Activity Recognition Challenge 2018</title>
    <!-- core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="css/main.css">

    <link href="https://fonts.googleapis.com/css?family=Roboto+Condensed:400,700" rel="stylesheet">
    <link href='http://fonts.googleapis.com/css?family=Droid+Sans+Mono' rel='stylesheet' type='text/css'>
    <!--[if lt IE 9]>
    <script src="../../js/html5shiv.js"></script>
    <script src="../../js/respond.min.js"></script>
    <![endif]-->
    <link rel="shortcut icon" media="all" type="image/x-icon" href="../../images/favicon.png" >

    <!-- Tracking code -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-56208223-2', 'auto');
      ga('send', 'pageview');

    </script>
</head><!--/head-->

<body id="challenge" class="challenge-page normal-page">
  <nav class="navbar navbar-expand-lg navbar-light">
    <div class="container"> 
    <a class="navbar-brand" href="#">
      <img src="images/ChallengeLogo.svg" class="d-inline-black-align-top" height="45" width="auto">
    </a>

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarContent" aria-controls="navbarContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarContent">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link" href="index.html">Home</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="people.html">People</a>
        </li>
        <li class="nav-item active">
          <a class="nav-link" href="challenge.html">Challenge</a>
        </li>
        <li class="nav-item">
          <a class="nav-link">Program</a>
        </li>
        <li class="nav-item">
          <a class="nav-link">Evaluation</a>
        </li>
        <li class="nav-item">
          <a class="nav-link">Contact</a>
        </li>
        <li class="nav-item">
          <a class="nav-link right-logo" href="http://cvpr2018.thecvf.com" target="_black">
            <img src="images/cvpr18logo.jpg" class="img-responsive cvpr-logo" height="45" width="auto">
          </a>
        </li>
      </ul>
    </div> <!-- collapse -->
    </div>
  </nav>

  <section class="normal-page-title challenge-title">
    <!-- <img class="title-banner" src="images/people_banner.svg" /> -->
    <div class="container">
      <div class="row">
        <div class="col-12 col-sm-12 col-md-12">
            <h1 class="title">Challenge Description</h1>
        </div>
      </div>
    </div>
  </section>

  <section class="guidelines">
    <div class="container">
      <div class="row">
        <div class="col-md-12 col-sm-12">
            <h2 class="section-title">Challenge Guidelines</h2>
            <p>
              To enter the competition, you need to create an account on the <a href="evaluation.html"> Evaluation</a>.
              Using a registered account you will be able to upload your results to the evaluation server and participate in the ActivityNet Challenge 2017. <strong class="line-through">Please be advised that we have changed our submission policy this year: each participant is limited to 1 submission per task per week. The Evaluation Server will enforce a waiting time of 7 days between submissions of the same task. This gives each participant a total of 3 submissions per task before the evaluation server closes.</strong> <strong> Each team is limited to 4 submissions (in total) per task.</strong> Only results that are submitted during the challenge period (before the deadline) and posted to the leaderboard will be considered valid. Additionally, you will also need to upload a notebook paper that describes your method in detail. This challenge allows the use of external data to train and tune algorithm parameters. We are committed to keeping track of this practice. Therefore, each submission must explicitly cite the kind of external data used and which modules benefit from it.
            </p>

        </div>
      </div>
    </div>
  </section>

  <section class="tasks flex-list">
    <div class="container">
      <div class="row">
        <div class="col-md-12 col-sm-12">
            <h2 class="section-title">Challenge Tasks</h2>

            <div class="row">
              <div class="col-12">
              <p>Therefore ActivityNet Large Scale Activity Recognition Challenge (ALSARC) 2018 includes five different tasks as described below:</p>
              </div>
            </div>

            <!-- Task 1 -->
            <div class="row">
              <div class="col-12">
                <div class="flex-list-item">
                  <div class="flex-item-icon">
                    <div class="image">
                      <img class="img-responsive" src="images/placeholder.svg"/>
                    </div>
                    <div class="text">
                      <h4>Task 1</h4>
                    </div>
                  </div>
                  <div class="flex-item-info">
                    <h4 class="name">Untrimmed Video Classification (ActivityNet)</h4>
                    <p class="description">
                      This task is intended to evaluate the ability of algorithms to predict activities in <strong>untrimmed</strong> video sequences. Here, videos can contain more than one activity, and typically large time lapses of the video are not related with any activity of interest.
                    </p>
                    <div class="flex-item-button">
                      <a href="#" class="box-animated-link">
                        <span>Details</span>
                      </a>
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <!-- Task 2 -->
            <div class="row">
              <div class="col-12">
                <div class="flex-list-item">
                  <div class="flex-item-icon">
                    <div class="image">
                      <img class="img-responsive" src="images/placeholder.svg"/>
                    </div>
                    <div class="text">
                      <h4 class="has-label">Task 2</h4>
                      <div class="label">New</div>
                    </div>
                  </div>
                  <div class="flex-item-info">
                    <h4 class="name">Trimmed Action Recognition (Kinetics)</h4>
                    <p class="description">
                      This task is intended to evaluate the ability of algorithms to recognize activities in <strong>trimmed</strong> video sequences. Here, videos contain a single activity, and all the clips have a standard duration of ten seconds. For this task, participants will use the Kinetics dataset, a new large-scale benchmark for trimmed action classification.
                    </p>
                    <div class="flex-item-button">
                      <a href="#" class="box-animated-link">
                        <span>Details</span>
                      </a>
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <!-- Task 3 -->
            <div class="row">
              <div class="col-12">
                <div class="flex-list-item">
                  <div class="flex-item-icon">
                    <div class="image">
                      <img class="img-responsive" src="images/placeholder.svg"/>
                    </div>
                    <div class="text">
                      <h4 class="has-label">Task 3</h4>
                      <div class="label">New</div>
                    </div>
                  </div>
                  <div class="flex-item-info">
                    <h4 class="name">Temporal Action Proposals (ActivityNet)</h4>
                    <p class="description">
                      This task is intended to evaluate the ability of algorithms to generate high quality <strong>action proposals</strong>. The goal is to produce a set of candidate temporal segments that are likely to contain a human action. 
                    </p>
                    <div class="flex-item-button">
                      <a href="#" class="box-animated-link">
                        <span>Details</span>
                      </a>
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <!-- Task 4 -->
            <div class="row">
              <div class="col-12">
                <div class="flex-list-item">
                  <div class="flex-item-icon">
                    <div class="image">
                      <img class="img-responsive" src="images/placeholder.svg"/>
                    </div>
                    <div class="text">
                      <h4>Task 4</h4>
                    </div>
                  </div>
                  <div class="flex-item-info">
                    <h4 class="name">Temporal Action Localization (ActivityNet)</h4>
                    <p class="description">
                      This task is intended to evaluate the ability of algorithms to <strong>temporally localize activities in untrimmed video sequences</strong>. Here, videos can contain more than one activity instance, and mutiple activity categories can appear in the video.
                    </p>
                    <div class="flex-item-button">
                      <a href="#" class="box-animated-link">
                        <span>Details</span>
                      </a>
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <!-- Task 5 -->
            <div class="row">
              <div class="col-12">
                <div class="flex-list-item">
                  <div class="flex-item-icon">
                    <div class="image">
                      <img class="img-responsive" src="images/placeholder.svg"/>
                    </div>
                    <div class="text">
                      <h4 class="has-label">Task 5</h4>
                      <div class="label">New</div>
                    </div>
                  </div>
                  <div class="flex-item-info">
                    <h4 class="name">Dense-Captioning Events in Videos (ActivityNet Captions)</h4>
                    <p class="description">
                      This task involves both <strong>detecting and describing events</strong> in a video. For this task, participants will use the ActivityNet Captions dataset, a new large-scale benchmark for dense-captioning events.
                    </p>
                    <div class="flex-item-button">
                      <a href="#" class="box-animated-link">
                        <span>Details</span>
                      </a>
                    </div>
                  </div>
                </div>
              </div>
            </div>
        </div>
      </div>
    </div>
  </section>

  <section class="data flex-list flex-list-reverse">
    <div class="container">
      <div class="row">
        <div class="col-md-12 col-sm-12">
            <h2 class="section-title">Additional Data</h2>
            <div class="sub-section" id="globalFeatures">
              <h3 class="subsection-title">Global features (Task 1, 3&ndash;5)</h3>

              <!-- ImageNet shuffle -->
              <div class="row">
                <div class="col-12">
                  <div class="flex-list-item">
                    <div class="flex-item-action">
                      <a href="#" class="ivul-btn action-btn">
                        <span>Download</span>
                      </a>
                    </div>
                    <div class="flex-item-info">
                      <h4 class="name">ImagenetShuffle</h4>
                      <p class="description">
                         We provide CNN features based on the <code>pool5</code> layer of a Google inception net (GoogLeNet) at a rate of 2FPS. Features are mean-pooled across the frames followed by L1-normalization.
                      </p>
                    </div>
                  </div>
                </div>
              </div>

              <!-- MBH feature -->
              <div class="row">
                <div class="col-12">
                  <div class="flex-list-item">
                    <div class="flex-item-action">
                      <a href="#" class="ivul-btn action-btn">
                        <span>Download</span>
                      </a>
                    </div>
                    <div class="flex-item-info">
                      <h4 class="name">MBH Feature</h4>
                      <p class="description">
                         The MBH features are generated with the aid of the Improved Trajectories executable with a provided implementation by the authors. Then, features are encoded using the GMM + Fisher Vectors pipeline.
                      </p>
                    </div>
                  </div>
                </div>
              </div>

            </div> <!-- #globalFeatures -->

            <div class="sub-section" id="frameBasedFeatures">
              <h3 class="subsection-title">Frame Based Features (Task 1, 3&ndash;5)</h3>

              <!-- C3D -->
              <div class="row">
                <div class="col-12">
                  <div class="flex-list-item">
                    <div class="flex-item-action">
                      <a href="#" class="ivul-btn action-btn">
                        <span>Download</span>
                      </a>
                    </div>
                    <div class="flex-item-info">
                      <h4 class="name">C3D</h4>
                      <p class="description">
                         The publicly available pre-trained C3D model, which has a temporal resolution of 16 frames, is used to extract frame based features. This network is not fine-tuned on the data in the challenge. We reduce the dimensionality of the activations from the second fully-connected layer (<code>fc7</code>) of the visual encoder from 4096 to 500 dimensions using PCA.
                      </p>
                    </div>
                  </div>
                </div>
              </div>

            </div> <!-- #frameBasedFeatures -->

            <div class="sub-section" id="temporalActionProposals">
              <h3 class="subsection-title">Temporal Action Proposals (Task 1, 3&ndash;5)</h3>

              <!-- Agnostic Temporal Activity Proposals -->
              <div class="row">
                <div class="col-12">
                  <div class="flex-list-item">
                    <div class="flex-item-action">
                      <a href="#" class="ivul-btn action-btn">
                        <span>Download</span>
                      </a>
                    </div>
                    <div class="flex-item-info">
                      <h4 class="name">Agnostic Temporal Activity Proposals</h4>
                      <p class="description">
                         We provide these proposals to encourage participation in the Activity Detection task. These proposals could be applied as a preliminary stage to split the untrimmed videos into high recall trimmed temporal segments.
                      </p>
                    </div>
                  </div>
                </div>
              </div>

            </div> <!-- #temporalActionProposals -->
        </div>
      </div>
    </div>
  </section>

  <section class="policy">
    <div class="container">
      <div class="row">
        <div class="col-md-12 col-sm-12">
            <h2 class="section-title">Use of External Data Policy</h2>
            <p>
              This challenge allows participants to use external data to train their algorithms or tune parameters. Each submission should explicitly cite the kind of external data used and which modules of the system benefit from it. Some popular forms of external data usage include (but not confined to): 
            </p>
            <ul>
              <li>additional videos or images for tuning parameters, and</li>
              <li>external modules like CNNs or DPMs trained with other datasets. </li>
            </ul>
            <p>If your case is not listed above, please contact us as soon as possible. </p>
        </div>
      </div>
    </div>
  </section>

  <section class="honor-code">
    <div class="container">
      <div class="row">
        <div class="col-md-12 col-sm-12">
            <h2 class="section-title">Honor Code</h2>
            <p>
               This academic challenge aims to highlight automated algorithms that understand the audio-visual content of videos. To serve this purpose and to allow for fair competition, we request that ALL participants: 
            </p>
            <ul>
              <li>generate results on the testing set by analyzing audio-visual content <strong>only</strong>,</li>
              <li><strong>not</strong> use the testing set for training or parameter tuning, and </li>
              <li>refrain from using <strong>any</strong> auxiliary information of the testing set (e.g. human annotations, URL metadata, etc.) other than the provided videos themselves. </li>
            </ul>
            <p>If a submission is found to violate any of the above guidelines, the challenge organizers reserve the right to disqualify the violating team.</p>
        </div>
      </div>
    </div>
  </section>

  <section class="award">
    <div class="container">
      <div class="row">
        <div class="col-md-12 col-sm-12">
            <h2 class="section-title">Most Innovative Solution</h2>
            <p>
               This year, we will award a <strong>Panasonic Lumix DC-GH5</strong> camera (+lens) and an <strong>NVidia</strong> graphics card to the participant with the most innovative solution. This solution does not necessarily have to be the winner of any task. A technical committee will make this decision based on the participants' submitted reports. So, please make sure to submit a detailed description of your solution on time.  
            </p>
        </div>
      </div>
    </div>
  </section>

  <footer class="footer">
    <!-- <img src="images/footer_pattern.svg" alt="" class="footer-pattern"> -->
    <div class="footer-content">
      <div class="container">
        <div class="row">
          <div class="col-md-4 col-xs-12">
            <img src="images/ChallengeLogo_White.svg" alt="" class="footer-logo">
          </div>
          <div class="col-md-4 col-xs-12">
            <ul class="footer-nav">
              <li class="nav-item">
                <a href="#">Home</a>
              </li>
              <li class="nav-item">
                <a href="#">People</a>
              </li>
              <li class="nav-item">
                <a href="#">Challenge</a>
              </li>
              <li class="nav-item">
                <a href="#">Program</a>
              </li>
              <li class="nav-item">
                <a href="#">Evaluation</a>
              </li>
              <li class="nav-item">
                <a href="#">About</a>
              </li>
            </ul>
          </div>
          <div class="col-md-4 col-xs-12">
            <div class="footer-text-section">
              <h4 class="footer-section-title">Contact</h4>
              <p class="footer-section-text">
                For general information or inquiry about the ActivityNet workshop (evaluation server, dates, or program), please contact <strong>Fabian Caba </strong> <a href="mailto:fabian.caba@kaust.edu.sa?Subject=ActivityNet Challenge Inquiry" target="_top">fabian.caba@kaust.edu.sa</a>
              </p>
            </div>
            <div class="footer-text-section">
              <h4 class="footer-section-title">FAQ</h4>
              <p class="footer-section-text">
                For ActivityNet Database FAQs visit our<a href="https://groups.google.com/forum/#!forum/activity-net" target="_blank"> Google Group.</a>
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </footer>
  <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" integrity="sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh" crossorigin="anonymous"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" integrity="sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ" crossorigin="anonymous"></script>

</body>
</html>
